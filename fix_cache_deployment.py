# fix_cache_deployment.py - A√±adir archivo de cache a servicios
"""
SOLUCION CORRECTA - A√ëADIR CACHE A DOCKER
==========================================
El problema es que simple_memory_cache.py no est√° en las im√°genes Docker.
Vamos a a√±adirlo correctamente a cada servicio.
"""

import os
import shutil

def create_cache_file():
    """Crear el archivo simple_memory_cache.py optimizado para producci√≥n"""
    
    cache_content = '''"""
Simple Memory Cache System for FirefighterAI
============================================
Sistema de cache en memoria thread-safe para optimizaci√≥n de performance
"""

import threading
import time
import hashlib
from typing import Any, Optional, Dict, Tuple
from functools import wraps

class SimpleMemoryCache:
    """Cache en memoria thread-safe con TTL y LRU"""
    
    def __init__(self, default_ttl: int = 300, max_size: int = 1000):
        self.default_ttl = default_ttl
        self.max_size = max_size
        self.cache: Dict[str, Tuple[Any, float]] = {}
        self.access_times: Dict[str, float] = {}
        self.lock = threading.RLock()
        print(f"‚úÖ Cach√© inicializado (TTL: {default_ttl}s, Max: {max_size} entradas)")
    
    def _cleanup_expired(self):
        """Limpiar entradas expiradas"""
        current_time = time.time()
        expired_keys = [
            key for key, (_, expiry) in self.cache.items()
            if expiry < current_time
        ]
        
        for key in expired_keys:
            self.cache.pop(key, None)
            self.access_times.pop(key, None)
    
    def _evict_lru(self):
        """Eliminar entrada menos usada recientemente"""
        if not self.access_times:
            return
            
        lru_key = min(self.access_times.items(), key=lambda x: x[1])[0]
        self.cache.pop(lru_key, None)
        self.access_times.pop(lru_key, None)
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """Establecer valor en cache"""
        if ttl is None:
            ttl = self.default_ttl
        
        expiry_time = time.time() + ttl
        
        with self.lock:
            # Limpiar expirados
            self._cleanup_expired()
            
            # Evict si necesario
            while len(self.cache) >= self.max_size:
                self._evict_lru()
            
            # A√±adir nueva entrada
            self.cache[key] = (value, expiry_time)
            self.access_times[key] = time.time()
    
    def get(self, key: str) -> Optional[Any]:
        """Obtener valor del cache"""
        with self.lock:
            self._cleanup_expired()
            
            if key not in self.cache:
                return None
            
            value, expiry = self.cache[key]
            
            if expiry < time.time():
                # Expirado
                self.cache.pop(key, None)
                self.access_times.pop(key, None)
                return None
            
            # Actualizar tiempo de acceso
            self.access_times[key] = time.time()
            return value
    
    def delete(self, key: str) -> bool:
        """Eliminar entrada del cache"""
        with self.lock:
            if key in self.cache:
                self.cache.pop(key, None)
                self.access_times.pop(key, None)
                return True
            return False
    
    def clear(self) -> None:
        """Limpiar todo el cache"""
        with self.lock:
            self.cache.clear()
            self.access_times.clear()
    
    def stats(self) -> Dict[str, Any]:
        """Obtener estad√≠sticas del cache"""
        with self.lock:
            self._cleanup_expired()
            
            total_entries = len(self.cache)
            usage_percent = (total_entries / self.max_size) * 100 if self.max_size > 0 else 0
            
            return {
                "total_entries": total_entries,
                "active_entries": total_entries,
                "expired_entries": 0,  # Ya limpiamos
                "max_size": self.max_size,
                "usage_percent": round(usage_percent, 1)
            }

# Instancia global del cache
memory_cache = SimpleMemoryCache()

def cache_result(ttl: int = 300, key_func=None):
    """Decorador para cachear resultados de funciones"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Generar clave de cache
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                # Clave basada en funci√≥n y argumentos
                func_name = f"{func.__module__}.{func.__name__}"
                args_str = str(args) + str(sorted(kwargs.items()))
                cache_key = f"{func_name}:{hashlib.md5(args_str.encode()).hexdigest()}"
            
            # Intentar obtener del cache
            result = memory_cache.get(cache_key)
            if result is not None:
                return result
            
            # Ejecutar funci√≥n y cachear resultado
            result = func(*args, **kwargs)
            memory_cache.set(cache_key, result, ttl)
            return result
        
        return wrapper
    return decorator

def cache_user_data(ttl: int = 300):
    """Decorador espec√≠fico para datos de usuario"""
    return cache_result(ttl=ttl, key_func=lambda user_id, *args, **kwargs: f"user:{user_id}")

def cache_cards_data(ttl: int = 180):
    """Decorador espec√≠fico para datos de cards"""
    return cache_result(ttl=ttl, key_func=lambda user_id, *args, **kwargs: f"cards:{user_id}")

def cache_chat_data(ttl: int = 120):
    """Decorador espec√≠fico para datos de chat"""
    return cache_result(ttl=ttl, key_func=lambda user_id, *args, **kwargs: f"chat:{user_id}")

def invalidate_user_cache(user_id: str) -> None:
    """Invalidar cache de usuario espec√≠fico"""
    patterns = [f"user:{user_id}", f"cards:{user_id}", f"chat:{user_id}"]
    
    for pattern in patterns:
        memory_cache.delete(pattern)

def get_cache_stats() -> Dict[str, Any]:
    """Obtener estad√≠sticas del cache"""
    return memory_cache.stats()

def clear_cache() -> None:
    """Limpiar todo el cache"""
    memory_cache.clear()

# Para compatibilidad con versiones anteriores
def cache_function(ttl=300):
    """Alias para cache_result"""
    return cache_result(ttl)
'''
    
    return cache_content

def add_cache_to_service(service_dir, service_name):
    """A√±adir archivo de cache a un servicio espec√≠fico"""
    
    if not os.path.exists(service_dir):
        print(f"‚ùå Directorio {service_dir} no encontrado")
        return False
    
    print(f"üìÅ A√±adiendo cache a {service_name}...")
    
    # Crear archivo de cache
    cache_file_path = os.path.join(service_dir, "simple_memory_cache.py")
    cache_content = create_cache_file()
    
    with open(cache_file_path, 'w', encoding='utf-8') as f:
        f.write(cache_content)
    
    print(f"   ‚úÖ {cache_file_path} creado")
    
    # Verificar que el archivo principal existe y tiene imports
    main_files = {
        "API": "api.py",
        "BO": "app.py", 
        "FO": "main.py"
    }
    
    main_file = os.path.join(service_dir, main_files.get(service_name, ""))
    
    if os.path.exists(main_file):
        with open(main_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if 'simple_memory_cache' in content:
            print(f"   ‚úÖ {main_files[service_name]} ya tiene imports de cache")
        else:
            print(f"   ‚ö†Ô∏è {main_files[service_name]} no tiene imports de cache")
    
    return True

def verify_dockerfiles():
    """Verificar que los Dockerfiles copian todos los archivos necesarios"""
    
    services = ["API", "BO", "FO"]
    
    for service in services:
        dockerfile_path = os.path.join(service, "Dockerfile")
        
        if os.path.exists(dockerfile_path):
            with open(dockerfile_path, 'r') as f:
                dockerfile_content = f.read()
            
            # Verificar que copia todos los archivos Python
            if "COPY *.py" in dockerfile_content or "COPY . ." in dockerfile_content:
                print(f"   ‚úÖ {service}/Dockerfile copia archivos Python correctamente")
            else:
                print(f"   ‚ö†Ô∏è {service}/Dockerfile podr√≠a no copiar simple_memory_cache.py")
                
                # A√±adir l√≠nea para copiar cache si no existe
                if "COPY simple_memory_cache.py" not in dockerfile_content:
                    print(f"   üí° Considera a√±adir: COPY simple_memory_cache.py ./")
        else:
            print(f"   ‚ö†Ô∏è {service}/Dockerfile no encontrado")

def main():
    print("üîß FIXING CACHE DEPLOYMENT")
    print("="*50)
    print("A√±adiendo simple_memory_cache.py a todos los servicios...")
    
    # Servicios a procesar
    services = [
        ("API", "API"),
        ("BO", "BO"), 
        ("FO", "FO")
    ]
    
    success_count = 0
    
    for service_dir, service_name in services:
        if add_cache_to_service(service_dir, service_name):
            success_count += 1
    
    print(f"\nüìä RESUMEN:")
    print(f"   ‚úÖ Servicios procesados: {success_count}/{len(services)}")
    
    # Verificar Dockerfiles
    print(f"\nüê≥ VERIFICANDO DOCKERFILES:")
    verify_dockerfiles()
    
    if success_count == len(services):
        print(f"\nüéâ CACHE DEPLOYMENT FIX COMPLETED!")
        print(f"")
        print(f"PR√ìXIMOS PASOS:")
        print(f"1. git add .")
        print(f"2. git commit -m 'FIX: Add simple_memory_cache.py to all services'")
        print(f"3. git push origin main")
        print(f"4. Esperar deploy (2-3 minutos)")
        print(f"5. Verificar servicios funcionando con cache")
        
        print(f"\nüìà PERFORMANCE ESPERADA:")
        print(f"   - MongoDB √≠ndices: 3-10x mejora (YA ACTIVA)")
        print(f"   - Memory cache: +3-5x mejora adicional") 
        print(f"   - Total: 15-50x mejora combinada")
    else:
        print(f"\n‚ùå ALGUNOS SERVICIOS FALLARON")
        print(f"Revisar errores arriba antes de proceder")

if __name__ == "__main__":
    main()