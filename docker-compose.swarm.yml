version: "3.8"

services:
  backend:
    image: ghcr.io/josojmf/ai-firefighter-backend:latest
    ports:
      - "5000:5000"
    env_file:
      - ./env/production.env
    environment:
      - PUBLIC_API_URL=http://backend:5000
      - ENVIRONMENT=production
      - DEBUG=false
      - DOCKER_ENV=true
    deploy:
      labels:
        app: firefighter
      restart_policy:
        condition: on-failure
    networks:
      - firefighter_network

  frontend:
    image: ghcr.io/josojmf/ai-firefighter-frontend:latest
    ports:
      - "8000:8000"
    env_file:
      - ./env/production.env
    environment:
      - API_BASE_URL=http://backend:5000
      - ENVIRONMENT=production
      - DEBUG=false
      - DOCKER_ENV=true
    depends_on:
      - backend
    deploy:
      labels:
        app: firefighter
      restart_policy:
        condition: on-failure
    networks:
      - firefighter_network

  backoffice:
    image: ghcr.io/josojmf/ai-firefighter-backoffice:latest
    ports:
      - "3001:3001"
    env_file:
      - ./env/production.env
    environment:
      - API_BASE_URL=http://backend:5000
      - ENVIRONMENT=production
      - DEBUG=false
      - DOCKER_ENV=true
      - MFA_ISSUER=FirefighterAI
    depends_on:
      - backend
    deploy:
      labels:
        app: firefighter
      restart_policy:
        condition: on-failure
    networks:
      - firefighter_network

  redis:
    image: redis:7-alpine
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis-data-prod:/data
    deploy:
      labels:
        app: firefighter
      restart_policy:
        condition: on-failure
    networks:
      - firefighter_network

networks:
  firefighter_network:
    driver: overlay

volumes:
  redis-data-prod:
    driver: local
